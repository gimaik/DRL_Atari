{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import keras\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn as sk\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import rescale\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *\n",
    "from keras import backend as K\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Global Parameters\n",
    "\n",
    "class DQN_Agent(): \n",
    "    \n",
    "    def __init__(self, num_state, num_action, params):\n",
    "        \n",
    "        self.params =  params\n",
    "        self.num_state = num_state\n",
    "        self.num_action = num_action\n",
    "        self.steps = 0        \n",
    "        self.gamma = params['gamma']   \n",
    "        self.eps_min = params['eps_min']\n",
    "        self.eps_max = params['eps_max']\n",
    "        self.eps = params['eps_max']\n",
    "        self.decay = params['decay']\n",
    "        self.learning_rate = params['lr']\n",
    "        self.batch_size = params['batch_size']\n",
    "        self.capacity = params['capacity']\n",
    "        self.load_model = params['load_model']\n",
    "        self.model = self._create_model(load = self.load_model)\n",
    "        self.model = self._create_model(load = self.load_model)\n",
    "        self.memory=[]\n",
    "        \n",
    "    # Model OK    \n",
    "    def _create_model(self, load = False):\n",
    "        \n",
    "        def huber_loss(y_true, y_pred, in_keras=True):\n",
    "            err = y_true - y_pred\n",
    "            delta = 2.0\n",
    "            quadratic_term = 0.5 * err**2\n",
    "            linear_term = delta*(abs(err) - 0.5*delta)\n",
    "            use_linear_term = (abs(err) > 1.0)\n",
    "            \n",
    "            if in_keras:\n",
    "                use_linear_term = K.cast(use_linear_term, 'float32')\n",
    "            return use_linear_term * linear_term + (1-use_linear_term) * quadratic_term\n",
    "            \n",
    "        if not load:\n",
    "            model =  Sequential()\n",
    "\n",
    "            model.add(Conv2D(input_shape = self.num_state, filters = 32, \n",
    "                             kernel_size = 8, strides=2, \n",
    "                             activation = 'elu'))\n",
    "\n",
    "            model.add(Conv2D(filters = 64, kernel_size = 4, strides=2, \n",
    "                             activation = 'elu'))\n",
    "\n",
    "            model.add(Conv2D(filters = 64, kernel_size = 2, strides=1,\n",
    "                             activation = 'elu'))\n",
    "\n",
    "            model.add(Flatten()) \n",
    "            model.add(Dense(units=512, kernel_initializer='glorot_normal',\n",
    "                            activation = 'relu')) \n",
    "            model.add(Dense(self.num_action))              \n",
    "\n",
    "            optimizer = Adam(lr = self.learning_rate)\n",
    "            model.compile(optimizer = optimizer, loss = huber_loss)\n",
    "\n",
    "            print(\"Model constructed...\", end =\"\\r\", flush=True)\n",
    "        else: \n",
    "            model = load_model('dqn-atari.h5', custom_objects={'huber_loss' : huber_loss})\n",
    "            print(\"Model loaded...\", end =\"\\r\", flush=True)\n",
    "        \n",
    "        return model   \n",
    "    \n",
    "    # Check OK\n",
    "    def predict(self, state):        \n",
    "        if len(state.shape) == 3:\n",
    "            state = np.expand_dims(state, axis=0)\n",
    "        return self.model.predict(state)\n",
    "    \n",
    "    # Check OK\n",
    "    def observe(self, state, action, next_state, reward, done):\n",
    "        self.memory.append((state, action, next_state, reward, done))    \n",
    "        \n",
    "        if len(self.memory) > self.capacity:\n",
    "            self.memory.pop(0)\n",
    "            \n",
    "        self.eps = self.eps_min + (self.eps_max - self.eps_min) * math.exp(-self.steps * self.decay)        \n",
    "        self.steps +=1        \n",
    "        \n",
    "    # Check OK    \n",
    "    def act(self, state):      \n",
    "        if np.random.rand() < self.eps:\n",
    "            return np.random.choice(self.num_action)\n",
    "        else:            \n",
    "            return np.argmax(self.predict(state))                 \n",
    "    \n",
    "    def replay(self):                \n",
    "        batch_len = min(self.batch_size, len(self.memory))        \n",
    "        batch = np.array(random.sample(self.memory, batch_len))        \n",
    "        \n",
    "        state = np.array([episode[0] for episode in batch])\n",
    "        action =  np.array([episode[1] for episode in batch])\n",
    "        next_state = np.array([episode[2] for episode in batch])\n",
    "        reward =  np.array([episode[3] for episode in batch])\n",
    "        done = np.array([episode[4] for episode in batch])\n",
    "        \n",
    "        q = np.array(self.predict(state))\n",
    "        q_ = np.array(self.predict(next_state))\n",
    "        \n",
    "        for i in range(batch_len):\n",
    "            q[i][action[i]] = reward[i]+ self.gamma*np.max(q_[i])* (1-done[i]) \n",
    "            \n",
    "        history = self.model.fit(state, q, \n",
    "                   verbose = 0, epochs=1, shuffle = False, batch_size = 32) \n",
    "        return history, np.mean(q, axis = 0)\n",
    "\n",
    "\n",
    "class input_pipeline():    \n",
    "    \n",
    "    def __init__(self, state):       \n",
    "        self.history_length = 4        \n",
    "        self.input_x=[]\n",
    "        self.input_x = [self._preprocess(state) for i in range(self.history_length)]\n",
    "        self.x = np.moveaxis(np.array(self.input_x), 0, -1) \n",
    "\n",
    "    def _preprocess(self, state):    \n",
    "        \n",
    "        state = np.mean(state, axis = 2).astype(np.uint8)\n",
    "        state = state[::2, ::2]\n",
    "        state = state[15:97,3:77]\n",
    "        state[state==162] = 80\n",
    "        state[state==180] = 90\n",
    "        state[state==198] = 100\n",
    "        state[state==200] = 110   \n",
    "        return state / 255\n",
    "    \n",
    "    def update(self, state):\n",
    "        self.input_x.pop(0)\n",
    "        self.input_x.append(self._preprocess(state))\n",
    "        self.x = np.moveaxis(np.array(self.input_x), 0, -1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(train=True):\n",
    "    \n",
    "    env = gym.make('BreakoutDeterministic-v4')\n",
    "    env = gym.wrappers.Monitor(env, './tmp/breakout-1', force=True)\n",
    "    num_state = env.observation_space.shape    \n",
    "    num_action = env.action_space.n\n",
    "    \n",
    "    agent = DQN_Agent((82,74,4), num_action, params) \n",
    "    loss, mean_av, render, iteration = [], [], False, 0    \n",
    "    \n",
    "    for episode in range(N_EPISODE):        \n",
    "        state, step, total_reward, done, render = env.reset(), 0, 0, False, False        \n",
    "        pipeline = input_pipeline(state)\n",
    "       \n",
    "        if episode > 5000:\n",
    "            render = True\n",
    "        \n",
    "        while not done:\n",
    "            if render:\n",
    "                env.render()\n",
    "                \n",
    "            state = pipeline.x\n",
    "            action = agent.act(state)            \n",
    "            next_state, reward, done, _ = env.step(action)  \n",
    "            \n",
    "            pipeline.update(next_state)\n",
    "            next_state = pipeline.x             \n",
    "            total_reward += reward\n",
    "            step +=1\n",
    "            \n",
    "            if train and step >= 4 :    \n",
    "                agent.observe(state, action, next_state, np.sign(reward), done)            \n",
    "                history, mean_action_value = agent.replay()\n",
    "                loss.append(history.history['loss'])\n",
    "                mean_av.append(np.mean(mean_action_value))                \n",
    "        \n",
    "        if episode % 10==0:\n",
    "            agent.model.save('dqn-atari.h5')\n",
    "        iteration+=step\n",
    "        \n",
    "        print('Episode: {}/{}, Step: {}, Iteration: {}, Reward: {}'\n",
    "              .format(episode+1, N_EPISODE, step, iteration, total_reward), \n",
    "              end = '\\r', flush = True) \n",
    "        \n",
    "    return np.array(loss), np.array(mean_av)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['gamma'] = 0.99\n",
    "params['eps_min'] = 0.10\n",
    "params['eps_max'] = 1.00\n",
    "params['decay'] = 5e-5\n",
    "params['batch_size'] = 64\n",
    "params['lr'] = 5e-4\n",
    "params['capacity'] = 10000\n",
    "params['load_model'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEYCAYAAACz2+rVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xl8XHW9//HXZ2ayN23SJi2lTZuW\nlqVAN8IOCrIIiKDoRVAQ3HAD9bri1Ye/q14X8Cc/RVBEr8JVBARFAUFEL4uAbUnpBl2gdG9Dm+7p\nmmU+vz/OSTotSTNJMzkzmffz8ZjHnPme75zzmdMm75zzPXOOuTsiIiIAsagLEBGR7KFQEBGRDgoF\nERHpoFAQEZEOCgUREemgUBARkQ4KBRER6aBQEBGRDgoFyUtmdpeZ/VfUdYhkG4WCSA4ysxVmdm7U\ndcjAo1AQyTJmloi6BslfCgXJaWY2xMzuNbONZtZkZnPN7E3/r81smpm9FPa5HyhOmXe4mf3BzBrN\nbLmZfeaA99aY2R/D+ZvM7Law/UYzez1c5kIze3fKe75kZn84YDm3mtmPu/gcK8zsK2Y2H9hpZomu\nlm9mvwHGAI+Y2Q4z+3I6n0MkHQoFyXU3AW3AWGAIcJW7J1M7mFkh8CfgN8BQ4AHgPeG8GPAIMA8Y\nBZwDfM7M3h7OjwOPAiuB2rDPfeGiXwfODNf7TeC3ZjYynPdb4AIzqwiXkwCuAP7nIJ/lSuAdQIW7\nt3a1fHe/GlgFvNPdB7n7zd19DpF0KRQk17UArwG73D3p7i930ucUoAD4kbu3uPuDwIvhvBOBanf/\nlrs3u/sy4BcEv8ABTgIOB77k7jvdfY+7Pwfg7g+4+7pwvfeHdZwUzmsAngX+LVzOBcBGd599kM9y\nq7uvdvfd3S2/E919DpG0KBQk1y0GvkhwyOXjXfQ5HFjr+18nfmX4PBY43My2tj+A/wBGhPNrgJXh\nX+77MbMPhoer2t93HFCV0uVu4Kpw+iqCPZWDWd3D5afq7nOIpEUDWpKzzOwS4Hpguru/dpCuDcAo\nM7OUYBhDcHhmNbDc3Sd28d7VwBgzS6QGg5mNJfhL/BzgX+7eZmZzAUt575+An5nZccDFwJe7+Ugd\noZXG8g+8EUp3n0MkLdpTkFx2HLAWWA9gZmPMrLKTfv8CWoHPmFmBmV3GvsMws4CmcJC3xMziZnac\nmZ2YMr8B+L6ZlZlZsZmdDpQR/GJuDNf9obCeDu6+B3gQ+B0wy91X9eCzdbf89cD4lNfdfQ6RtCgU\nJJf9GmgGVoeHS/5IJ3u/7t4MXAZcC2wG3hf2xd3bCP6KnwosBzYCvyQY3G2f/05gAsHg7hrgfe6+\nEPghQeCsB44Hnu+kxrvDed0dOjqw5u6W/z3g6+Ghoi929zlE0mW6HadI5pjZGIJxj8PcfXvU9Yh0\nR3sKIhkSnib6eeA+BYLkCg00i2SAmZURHPZZSXA6qkhO0OEjERHpoMNHIiLSIecOH1VVVXltbW3U\nZYiI5JTZs2dvdPfq7vrlXCjU1tZSX18fdRkiIjnFzFZ230uHj0REJIVCQUREOigURESkg0JBREQ6\nKBRERKRDxkLBzH5lZhvMrLObnmCBW81sqZnNN7PpmapFRETSk8k9hbs4+Nf7LwQmho/rgJ9lsBYR\nEUlDxkLB3Z8luExxVy4F/scDM4CKlPvb9rnZKzdz018Xo8t6iIh0LcoxhVHsf/vBNWHbm5jZdWZW\nb2b1jY2NvVrZy2u387OnX6dh255evV9EJB/kxECzu9/p7nXuXldd3e23tDs1paYCgLmrt/ZlaSIi\nA0qUobCW4Kbo7UaHbRlxzMhyCuMx5ikURES6FGUoPAx8MDwL6RRgm7s3ZGplRYk4xxw+mDkKBRGR\nLmXsgnhmdi9wFlBlZmuA/wMUALj7HcBjwEXAUmAX8KFM1dJuWk0F97+4mta2JIl4Thw5ExHpVxkL\nBXe/spv5Dnw6U+vvzJSaIdz1wgpe27CDY0YO7s9Vi4jkhLz6c3lqTSWAxhVERLqQV6FQO6yUISUF\nOgNJRKQLeRUKZsaUmgqFgohIF/IqFACm1lTw6vomdu5tjboUEZGsk4ehMISkw4K126IuRUQk6+Rd\nKEwZHXyzWYPNIiJvlnehMGxQETVDSzSuICLSibwLBQhOTdWegojIm+VpKFSwbtse1m/XFVNFRFLl\nZShMHxOMK8xeuSXiSkREsktehsKxhw+hKBGjfoVCQUQkVV6GQmEixpSaCmavUiiIiKTKy1AAOGFs\nJa+s3cbu5raoSxERyRp5Gwp1YytpTTrz1ugsJBGRdnkbCieMDa6YqsFmEZF98jYUKkoLmTB8EPUr\nNkddiohI1sjbUIDgENJLq7aSTHrUpYiIZIW8DoUTxlaybXcLrzfuiLoUEZGskNehUFc7FIB6jSuI\niAB5Hgq1w0oZVlaoL7GJiITyOhTMjOljK5m9UoPNIiKQ56EAwWDzik27aGzaG3UpIiKRUyi0jyvo\n1FQREYXC5NFDKCmIM3O5QkFEJO9DoSAeo662khnLNkVdiohI5PI+FABOGT+MxW80sWVnc9SliIhE\nSqEAnDwuGFfQISQRyXcKBWDy6AqKC2LMXK5DSCKS3xQKBDfdOWFsJTOWaU9BRPKbQiF08rhhLH5j\nO1t3aVxBRPKXQiF0yvhhuMMsjSuISB5TKISm1AyhKBHTYLOI5DWFQqgoEWf6GH1fQUTym0Ihxcnj\nh7KwYTvbdrdEXYqISCQUCinaxxVmam9BRPJURkPBzC4wsyVmttTMbuxk/hgze8rM5pjZfDO7KJP1\ndGfamApKCuK88LpCQUTyU8ZCwcziwO3AhcAk4Eozm3RAt68Dv3f3acAVwE8zVU86ihJxTho3lH++\n1hhlGSIikcnknsJJwFJ3X+buzcB9wKUH9HFgcDg9BFiXwXrScsaEKl5v3EnDtt1RlyIi0u8yGQqj\ngNUpr9eEban+E7jKzNYAjwE3dLYgM7vOzOrNrL6xMbN/xZ8xsQqA517bmNH1iIhko6gHmq8E7nL3\n0cBFwG/M7E01ufud7l7n7nXV1dUZLeioEeVUDSrk+aUKBRHJP5kMhbVATcrr0WFbqo8Avwdw938B\nxUBVBmvqVixmnD6hiueWbsLdoyxFRKTfZTIUXgQmmtk4MyskGEh++IA+q4BzAMzsGIJQiHyU9/QJ\nVWzcsZcl65uiLkVEpF9lLBTcvRW4HngCWERwltErZvYtM7sk7PYF4GNmNg+4F7jWs+DP8zMmaFxB\nRPJTIpMLd/fHCAaQU9u+kTK9EDg9kzX0xuEVJYyvLuO5pRv56Jnjoy5HRKTfRD3QnLXOnFDFzGWb\n2dvaFnUpIiL9RqHQhdMnVLG7pY2XVm6NuhQRkX6jUOjCqUcMIxEzntW3m0UkjygUulBeXEBdbSVP\nLd4QdSkiIv1GoXAQZx81nMVvNOmSFyKSNxQKB3H20cMBeHqJDiGJSH5QKBzExOGDGFVRokNIIpI3\nFAoHYWacdVQ1zy/dSHNrMupyREQyTqHQjbOPGs7O5jbqV2yOuhQRkYxTKHTjtAnDKIzHeGqJDiGJ\nyMCnUOhGaWGCk8cP5SkNNotIHlAopOGso4azdMMOVm/eFXUpIiIZpVBIw9lHBTf20SEkERnoFApp\nGFdVxviqMp5cuD7qUkREMkqhkAYz47xjR/Cv1zexbXdL1OWIiGSMQiFN5086jNak87QOIYnIAKZQ\nSNO0mgqqBhXxNx1CEpEBTKGQpljMOG/SCJ5evEE33hGRAUuh0APnTxrBzuY2Xnh9U9SliIhkhEKh\nB049YhhlhXGdhSQiA5ZCoQeKC+KcddRwnly4nmTSoy5HRKTPKRR66PxjR9DYtJe5a3TvZhEZeBQK\nPXTWUcNJxIwnXnkj6lJERPqcQqGHhpQUcPqEKh5b0IC7DiGJyMCiUOiFd0weyerNu1mwdlvUpYiI\n9CmFQi+8fdJhFMSNv8xviLoUEZE+pVDohSGlBZwxoYpH5+sQkogMLAqFXnrH5MNZu3U3c1frLCQR\nGTgUCr103qQROoQkIgOOQqGXhpQU8JaJ1Ty2oEFfZBORAUOhcAgunjKSddv2MEeHkERkgFAoHIJz\njxlBYSLGo/PXRV2KiEifUCgcgvLiAs46sppH5jXQ2paMuhwRkUOmUDhEl00fxcYde3lu6caoSxER\nOWQKhUN09tHDGVJSwENz1kZdiojIIUsrFMzsdDN70sxeNbNlZrbczJal8b4LzGyJmS01sxu76HO5\nmS00s1fM7Hc9/QBRK0rEecfkkTzxyhvs2NsadTkiIock3T2F/wZuAc4ATgTqwucumVkcuB24EJgE\nXGlmkw7oMxH4KnC6ux8LfK5H1WeJy6aNYk9Lkr++rCunikhuSzcUtrn74+6+wd03tT+6ec9JwFJ3\nX+buzcB9wKUH9PkYcLu7bwFw9w09qj5LnDC2kjFDS3lozpqoSxEROSTphsJTZvYDMzvVzKa3P7p5\nzyhgdcrrNWFbqiOBI83seTObYWYXdLYgM7vOzOrNrL6xsTHNkvuPmfGuaaN44fVNNGzbHXU5IiK9\nlm4onExwyOi7wA/Dx//tg/UngInAWcCVwC/MrOLATu5+p7vXuXtddXV1H6y277172ijc4c9z9Z0F\nEcldiXQ6ufvZvVj2WqAm5fXosC3VGmCmu7cAy83sVYKQeLEX64vUuKoypo2p4A+z1/Dxt4zHzKIu\nSUSkx9I9+2iImd3SfgjHzH5oZkO6eduLwEQzG2dmhcAVwMMH9PkTwV4CZlZFcDip27OastXldTW8\ntmEHL63SZS9EJDele/joV0ATcHn42A78+mBvcPdW4HrgCWAR8Ht3f8XMvmVml4TdngA2mdlC4Cng\nS2kMYGetd045nNLCOPe/uCrqUkREesXSuUmMmc1196ndtfWHuro6r6+v7+/Vpu0rD87n4XnrmPW1\ncygvLoi6HBERAMxstrvXddcv3T2F3WZ2RsrCTwd0mk0nrjipht0tbTwyT/dZEJHck24ofBK43cxW\nmNlK4DbgE5krK3dNrangqBHl3KdDSCKSg9IKBXef6+5TgMnA8e4+zd3nZba03GRmXHFSDfPXbOOV\ndduiLkdEpEcOekqqmX2+i3YA3P2WDNSU8949bRTfe3wx97+4mm9d2t1JWiIi2aO7PYXybh7SiYrS\nQi487jAemrOWXc26SJ6I5I6D7im4+zf7q5CB5qpTxvLnuev405x1vP/kMVGXIyKSlu4OH33Z3W82\ns58Abzp31d0/k7HKclzd2EomjRzM3S+s4MqTavQNZxHJCd0dPloUPtcDszt5SBfMjGtOG8uS9U3M\nXL456nJERNLS3eGjR8Lnu9vbzCwGDHL37RmuLeddOjUYcL77hRWcMn5Y1OWIiHQr3Wsf/c7MBptZ\nGfAysNDMvpTZ0nJfcUGc951Yw98WrmfdVn3XT0SyX7pfXpsU7hm8C3gcGAdcnbGqBpCrTh6Lu3PP\nzJVRlyIi0q10Q6HAzAoIQuHh8FLX3V80SagZWso5x4zg3lmr2dPSFnU5IiIHlW4o/BxYAZQBz5rZ\nWIIrpUoaPnR6LZt3NvPQnANvJyEikl3SvczFre4+yt0v8sBKoDc33slLp44fxvGjhvCLZ5eRTGoH\nS0SyV7oDzcPM7FYze8nMZpvZjwFdvyFNZsZ1bxnPso07eXLR+qjLERHpUrqHj+4DGoH3AO8Np+/P\nVFED0YXHHUbN0BLufDZnbywnInkg3VAY6e7fdvfl4eO/gBGZLGygScRjfPSM8cxeuYX6Ffoym4hk\np3RD4W9mdoWZxcLH5QS30pQe+Le60VSWFvBz7S2ISJZKNxQ+BtwD7A0f9wEfN7MmM9NZSGkqLUxw\n9am1PLlwPUs3NEVdjojIm6QbCkOAa4Fvu3sBUAuc6+7l7j44Q7UNSNecOpaSgji3P/V61KWIiLxJ\nuqFwO3AKcGX4uonglpzSQ8MGFXH1qWP589y1LGvcEXU5IiL7STcUTnb3TwN7ANx9C1CYsaoGuI+d\nOZ7CRIzbnloadSkiIvtJNxRazCxOeGkLM6sGkhmraoCrLi/iqpODm/Cs2Lgz6nJERDqkGwq3Ag8B\nw83sO8BzwHczVlUeuO6t40nETHsLIpJV0r3MxT3Al4HvAQ3Au9z9gUwWNtANLy/mAyeP5aE5a1m5\nSXsLIpId0t1TwN0Xu/vt7n6buy/q/h3SnU+Eews//vtrUZciIgL0IBSk7w0fXMy1p9fy0Ny1LGrQ\n1z1EJHoKhYh96q0TKC9KcPNfF0ddioiIQiFqQ0oL+NTZE3hqSSMzlm2KuhwRyXMKhSxw7Wm1HDa4\nmO8/vhh33W9BRKKjUMgCxQVx/v28icxdvZUnXnkj6nJEJI8pFLLEe6aPZsLwQXz/8cU0t+p7gSIS\nDYVClkjEY3z9HcewYtMufv388qjLEZE8pVDIImcdNZxzjh7OT/53KRua9kRdjojkIYVClvn6xZPY\n29rGzX9dEnUpIpKHMhoKZnaBmS0xs6VmduNB+r3HzNzM6jJZTy4YV1XGh88Yx4Oz1zB39daoyxGR\nPJOxUAivqno7cCEwCbjSzCZ10q8c+CwwM1O15Job3jaR6vIi/vPhV0gmdYqqiPSfTO4pnAQsdfdl\n7t5McAvPSzvp923gJsJ7NQgMKkrw1QuPZu7qrfxu1qqoyxGRPJLJUBgFrE55vSZs62Bm04Ead//L\nwRZkZteZWb2Z1Tc2NvZ9pVno3dNGcfqEYdz0+GLWb1deikj/iGyg2cxiwC3AF7rr6+53unudu9dV\nV1dnvrgsYGZ8513H09yW5JuPvBJ1OSKSJzIZCmuBmpTXo8O2duXAccDTZraC4B7QD2uweZ/aqjI+\nc85EHlvwBn9fuD7qckQkD2QyFF4EJprZODMrBK4AHm6f6e7b3L3K3WvdvRaYAVzi7vUZrCnnfOzM\n8Rw1opxv/PllduxtjbocERngMhYK7t4KXA88ASwCfu/ur5jZt8zskkytd6ApTMT47mXH07B9D999\nTPc2EpHMSmRy4e7+GPDYAW3f6KLvWZmsJZedMLaS684cz8+fXcZ5k0Zw9lHDoy5JRAYofaM5R/z7\neUdy5IhBfOXB+Wzd1Rx1OSIyQCkUckRxQZxbLp/K5p3NfOPPOhtJRDJDoZBDjhs1hM+eM5GH563j\n0fnroi5HRAYghUKO+eRZRzC1poKv/nEBqzfvirocERlgFAo5JhGP8ZMrpwFw/e9e0g15RKRPKRRy\nUM3QUn7w3snMW7ONm/+6OOpyRGQAUSjkqAuOG8k1p47ll88t17edRaTPKBRy2FcvOoZjDx/MFx6Y\nx6pNGl8QkUOnUMhhxQVxfvqB6QBc95t6duoyGCJyiBQKOW7ssDJue/80Xl3fxJcenIe7bsojIr2n\nUBgAzpxYzVcvPIbHFrzB7U8tjbocEclhGb32kfSfj545joUN2/nhk69y5Ihyzj/2sKhLEpEcpD2F\nAcLM+N5lxzN5dAWfuW8Oc1ZtibokEclBCoUBpLggzn9fU8fw8mI+cnc9KzbujLokEckxCoUBpmpQ\nEXd/+CTcnWt/PYtNO/ZGXZKI5BCFwgA0rqqMX15zIg3b9vDhu+t1xzYRSZtCYYA6YWwlP7lyGi+v\n3cZH7nqR3c1tUZckIjlAoTCAnX/sYdxy+RRmrdjMdb+pZ2+rgkFEDk6hMMBdOnUUN71nMv98bSOf\nvmcOLW26qqqIdE2hkAcur6vh25cey98XrefT97ykPQYR6ZJCIU9cfWot37zkWP62cD0fvbteYwwi\n0imFQh655rRabn7PZJ5fupFrfjWLpj0tUZckIllGoZBnLj+xhh9fMY2XVm3hql/O1PcYRGQ/CoU8\n9M4ph3PHVSew+I0mLvvZCyxr3BF1SSKSJRQKeercSSO497pTaNrTymU/e4H6FZujLklEsoBCIY9N\nH1PJQ586jcrSQt7/y5k8Mm9d1CWJSMQUCnlu7LAy/vjJ05gyegg33DuH7z++mLakbtQjkq8UCkJl\nWSG//ejJfODkMdzxzOtc++tZbNnZHHVZIhIBhYIAUJSI8513H89N7zmemcs2887bnuPltduiLktE\n+plCQfbzvhPH8PtPnEpb0nn3T5/nl/9cRlKHk0TyhkJB3mRqTQV/+cyZvPXI4fzXXxbxobtepLFJ\n32cQyQcKBenU0LJCfvHBE/j2u45jxrJNXPjjZ/nHovVRlyUiGaZQkC6ZGVefMpZHbjiDqkFFfOTu\nej533xw2axBaZMBSKEi3jhxRzsPXn8Hnzp3IXxY0cN4tz/Do/HW4a6xBZKBRKEhaChMxPnfukTxy\nwxmMqizh+t/N4aN317Ny086oSxORPpTRUDCzC8xsiZktNbMbO5n/eTNbaGbzzewfZjY2k/XIoTv6\nsMH88ZOn8bWLjmHGsk2cd8uz/OCJxexq1n2gRQaCjIWCmcWB24ELgUnAlWY26YBuc4A6d58MPAjc\nnKl6pO8k4jE+9pbx/O8Xz+Idk0dy+1Ovc84Pn+HPc9fq9FWRHJfJPYWTgKXuvszdm4H7gEtTO7j7\nU+6+K3w5AxidwXqkj40YXMz/e99UHvjEqVSWFvLZ++byztue45lXGzXeIJKjMhkKo4DVKa/XhG1d\n+QjweGczzOw6M6s3s/rGxsY+LFH6wom1Q3nkhjO45fIpbNvdwjW/msWVv5jBS6u2RF2aiPRQVgw0\nm9lVQB3wg87mu/ud7l7n7nXV1dX9W5ykJR4zLps+mn984a1885JjWbphB5f99AWu/u+ZzFi2SXsO\nIjkik6GwFqhJeT06bNuPmZ0LfA24xN31tdkcV5SIc81ptTzzpbP5ygVHs6ihiSvunMF77/gX/7t4\nvcJBJMtZpn5IzSwBvAqcQxAGLwLvd/dXUvpMIxhgvsDdX0tnuXV1dV5fX5+BiiUT9rS08UD9au54\nZhlrt+7myBGD+OCptVw2fRSlhYmoyxPJG2Y2293ruu2Xyb/czOwi4EdAHPiVu3/HzL4F1Lv7w2b2\nd+B4oCF8yyp3v+Rgy1Qo5KaWtiQPz13Hr55fzivrtlNenODyuhquPmUstVVlUZcnMuBlRShkgkIh\nt7k7L63awl0vrOTxBQ20uXP6EVX8W91ozp90GCWF8ahLFBmQFAqS9TZs38O9s1bzwOzVrNmym/Ki\nBBdPGcl7TxjN9DGVmFnUJYoMGAoFyRnJpDNz+WYenL2GxxY0sLuljZqhJVx03EguOn4kk0cPUUCI\nHCKFguSkHXtbeXxBA39Z0MBzr22kNemMqijhouMP44LjRjK1poJ4TAEh0lMKBcl523a18OSi9Ty2\noIF/vtZIS5tTWVrAW4+s5uyjh/OWidVUlhVGXaZITlAoyICybXcLz77ayFNLNvDMkkY27WwmZsFd\n4s6YWM0p44cyfUwlxQUaqBbpjEJBBqxk0pm/dhtPLd7A00s2sGDtNpIOhfEYU8dUcMr4YZwyfijT\naip1NpNISKEgeWP7nhbqV2xmxrLNzFi2iZfDkIjHjKNGlDN1TAVTayqYVlPBEdWDiGlMQvKQQkHy\nVntIvLRyK3NXb2Xe6q007Q3u91BelOD40UM4ZuRgjj6snGNGDmbC8EE67CQDXrqhoOsMyIAzuLiA\ntx09grcdPQIIDjct27iDOauCkFiwdhu/nbGSva1JINijOKK6jKMPG8zRI8sZXzWII6rLGDOslKKE\nwkLyi/YUJC+1JZ3lG3ey+I3tLG5oYlHDdha/0cTarbs7+sQMaoaWMr6qjPHVgxhfXUbtsDJGV5Yw\nckgJhYmsuMiwSFq0pyByEPGYMWH4ICYMH8TFk/e1N+1pYfnGnSxr3Mmyxh28Hk7/a9km9rQkO/qZ\nwYjyYkZXloSPUkZXlnB4RQmHDSlmRHkxg0sS+tKd5ByFgkiK8uICJo+uYPLoiv3ak0mnYfseVm/e\nxZotu1mzZd9z/cotPDK/gbYDbkVamIgxYnARI8qLGTG4mOryIkYMLmZ4eRHDBhUytKyQytJChg0q\npKQgrgCRrKBQEElDLGaMqihhVEVJp/Nb25K8sX0Pa7fsZkPTXtZv38OGpr1s2L6H9dv3suiN7Tz7\n6t6OAe8DFSViHSExtKyQyrJChpYWUFFaSHlxgsHFBZQXJygvLmBwSfAcvE5o3EP6lEJBpA8k4rHw\nEFLpQfvt3NvKhqa9bN7ZzJadzWze1bxvemczW8LXa7fuZvPOZrbtbul23UWJWBAWxQkGFScoKYhT\nWhintDBBSWEwXVIYp7Qg0TFdVhSnJHxdWhinuCBOcUGMwnicooIYRYkYhYkYRYm4LiuSZxQKIv2o\nrCjBuKIE49K8h0Rb0tmxt5WmPS1s3x08N+1ppWlv8Lx9d/i8J5i3Y28ru5rb2LijmV3Nu9jd3Mau\nljZ2NbfR3JrsfoWdiMcsJSSCoGifTm0riMcoiBvxmFEQj5GIGYmu2mJGPG4UxGIk4kFbImYk2vvF\njUQsaIvHDLOgjpgFj2A62IOLh22xGCnzgvkd0+392vukvCd1uTEDS3nORwoFkSwWjxlDSgoYUlIA\nlYe2rNa2JLta2oKgaG5jV3NrynQbzW1JmluT7G1tC5/3vd7bkqS5LbnvOaXP3pYkW3e30NyapLUt\nSVvSaUkmaW1zWtqc1mSStrZ9ba3J3Drj0QyMICSMIFToaAPDOvrsP2//9iBjLGV5wXtTA8hs/2XG\nwnW2L/Nz5x7JO6ccntHPq1AQyROJeIzB8RiDiwsircPdaUsG4dDSFoZHMgiTIEiStIbTrckkSQ/2\nmNrf1+aOh23BtNOWTOnjTtKDkwPakk7Sg0dbko7pZNJpC/sk29+TDN7nDk4wjTvhE46Hz8FyCKfd\n97W7h/Pa29l/ecGssH/KMpPh9H7LTFle+DYqSjP/b6dQEJF+ZWbhISP0TfIspG/fiIhIB4WCiIh0\nUCiIiEgHhYKIiHRQKIiISAeFgoiIdFAoiIhIB4WCiIh0yLmb7JhZI7Cyl2+vAjb2YTmZkO01Znt9\noBr7QrbXB9lfY7bVN9bdq7vrlHOhcCjMrD6dOw9FKdtrzPb6QDX2hWyvD7K/xmyvrys6fCQiIh0U\nCiIi0iHfQuHOqAtIQ7bXmO31gWrsC9leH2R/jdleX6fyakxBREQOLt/2FERE5CAUCiIi0iFvQsHM\nLjCzJWa21MxuzPC6aszsKTPoTQ14AAAG90lEQVRbaGavmNlnw/ahZvakmb0WPleG7WZmt4a1zTez\n6SnLuibs/5qZXZPSfoKZLQjfc6v14oayZhY3szlm9mj4epyZzQyXeb+ZFYbtReHrpeH82pRlfDVs\nX2Jmb09pP+TtbWYVZvagmS02s0VmdmoWbsN/D/+NXzaze82sOOrtaGa/MrMNZvZySlvGt1tX60iz\nvh+E/87zzewhM6vo7bbpzfZPp8aUeV8wMzezqqi2YUZ5eDu7gfwA4sDrwHigEJgHTMrg+kYC08Pp\ncuBVYBJwM3Bj2H4jcFM4fRHwOMFtWE8BZobtQ4Fl4XNlOF0ZzpsV9rXwvRf2os7PA78DHg1f/x64\nIpy+A/hkOP0p4I5w+grg/nB6Urgti4Bx4TaO99X2Bu4GPhpOFwIV2bQNgVHAcqAkZftdG/V2BN4C\nTAdeTmnL+Hbrah1p1nc+kAinb0qpr8fbpqfbP90aw/Ya4AmCL9BWRbUNM/no91/QUTyAU4EnUl5/\nFfhqP67/z8B5wBJgZNg2ElgSTv8cuDKl/5Jw/pXAz1Pafx62jQQWp7Tv1y/NmkYD/wDeBjwa/ufc\nmPKD2bHNwh+CU8PpRNjPDtyO7f36YnsDQwh+4doB7dm0DUcBq8Mf+kS4Hd+eDdsRqGX/X7oZ325d\nrSOd+g6Y927gns4+c3fbpjf/j3tSI/AgMAVYwb5QiGQbZuqRL4eP2n94260J2zIu3EWdBswERrh7\nQzjrDWBEN/UdrH1NJ+098SPgy0AyfD0M2OrurZ0ss6OOcP62sH9P6+6JcUAj8GsLDnH90szKyKJt\n6O5rgf8LrAIaCLbLbLJrO7brj+3W1Tp66sMEfz33pr7e/D9Oi5ldCqx193kHzMrGbdhr+RIKkTCz\nQcAfgM+5+/bUeR78KRDJ+cBmdjGwwd1nR7H+NCUIdt9/5u7TgJ0Eu9MdotyGAOHx3ksJAuxwoAy4\nIKp60tUf26236zCzrwGtwD19XtQhMLNS4D+Ab/TXOqP6/50vobCW4Fhgu9FhW8aYWQFBINzj7n8M\nm9eb2chw/khgQzf1Hax9dCft6ToduMTMVgD3ERxC+jFQYWaJTpbZUUc4fwiwqRd198QaYI27zwxf\nP0gQEtmyDQHOBZa7e6O7twB/JNi22bQd2/XHdutqHWkxs2uBi4EPhL8Qe1PfJnq+/dNxBEH4zwt/\nbkYDL5nZYb2oMWPbsE/09/GqKB4Ef3UuI/hHbR+UOjaD6zPgf4AfHdD+A/YfRLo5nH4H+w9UzQrb\nhxIcV68MH8uBoeG8AweqLuplrWexb6D5AfYfoPtUOP1p9h+g+304fSz7DwIuIxgA7JPtDfwTOCqc\n/s9w+2XNNgROBl4BSsNl3A3ckA3bkTePKWR8u3W1jjTruwBYCFQf0K/H26an2z/dGg+Yt4J9YwqR\nbMNMPfp1ZVE+CM4QeJXgjIWvZXhdZxDs9s0H5oaPiwiOX/4DeA34e8p/EANuD2tbANSlLOvDwNLw\n8aGU9jrg5fA9t3GQAbNuaj2LfaEwPvzPujT8wSoK24vD10vD+eNT3v+1sIYlpJy90xfbG5gK1Ifb\n8U/hD1ZWbUPgm8DicDm/IfjlFel2BO4lGONoIdjj+kh/bLeu1pFmfUsJjr+3/7zc0dtt05vtn06N\nB8xfwb5Q6PdtmMmHLnMhIiId8mVMQURE0qBQEBGRDgoFERHpoFAQEZEOCgUREemgUJC8ZWYvhM+1\nZvb+Pl72f3S2LpFsp1NSJe+Z2VnAF9394h68J+H7rq/T2fwd7j6oL+oT6U/aU5C8ZWY7wsnvA2ea\n2VwL7o8QD6/v/2J4ffyPh/3PMrN/mtnDBN++xcz+ZGazLbinwnVh2/eBknB596SuK7z2/g8suP/C\nAjN7X8qyn7Z994+4p/0a+yL9KdF9F5EB70ZS9hTCX+7b3P1EMysCnjezv4V9pwPHufvy8PWH3X2z\nmZUAL5rZH9z9RjO73t2ndrKuywi+qT0FqArf82w4bxrBZR3WAc8TXEfpub7/uCJd056CyJudD3zQ\nzOYSXPJ8GDAxnDcrJRAAPmNm84AZBBc/m8jBnQHc6+5t7r4eeAY4MWXZa9w9SXCph9o++TQiPaA9\nBZE3M+AGd39iv8Zg7GHnAa/PJbhxyy4ze5rg+jq9tTdlug39fEoEtKcgAk0Et01t9wTwyfDy55jZ\nkeENfg40BNgSBsLRBFe9bNfS/v4D/BN4XzhuUU1w28dZffIpRPqA/hIRCa7C2hYeBrqL4N4StQTX\nyzeCO8C9q5P3/RX4hJktIriC54yUeXcC883sJXf/QEr7QwS3iJxHcCXdL7v7G2GoiEROp6SKiEgH\nHT4SEZEOCgUREemgUBARkQ4KBRER6aBQEBGRDgoFERHpoFAQEZEO/x99FpowFGoHuwAAAABJRU5E\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd881a26a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.array(range(150000))\n",
    "y = params['eps_min'] + (params['eps_max']-params['eps_min'])*np.exp(-params['decay']*x)\n",
    "plt.plot(y)\n",
    "plt.title('$\\epsilon$ decay rate')\n",
    "plt.ylabel('epsilon')\n",
    "plt.xlabel('iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-22 18:10:05,532] Making new env: BreakoutDeterministic-v4\n",
      "[2017-11-22 18:10:05,667] Clearing 17 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded...\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-22 18:10:06,989] Starting new video recorder writing to /home/thomas/Projects/Reinforcement Learning/tmp/breakout-1/openaigym.video.0.4405.video000000.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1/15000, Step: 129, Iteration: 129, Reward: 0.0\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-22 18:10:12,322] Starting new video recorder writing to /home/thomas/Projects/Reinforcement Learning/tmp/breakout-1/openaigym.video.0.4405.video000001.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 8/15000, Step: 200, Iteration: 1388, Reward: 2.0\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-22 18:11:00,406] Starting new video recorder writing to /home/thomas/Projects/Reinforcement Learning/tmp/breakout-1/openaigym.video.0.4405.video000008.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 27/15000, Step: 261, Iteration: 4581, Reward: 3.0\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-22 18:13:02,948] Starting new video recorder writing to /home/thomas/Projects/Reinforcement Learning/tmp/breakout-1/openaigym.video.0.4405.video000027.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 64/15000, Step: 248, Iteration: 13168, Reward: 3.0\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-22 18:18:35,566] Starting new video recorder writing to /home/thomas/Projects/Reinforcement Learning/tmp/breakout-1/openaigym.video.0.4405.video000064.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 125/15000, Step: 230, Iteration: 26944, Reward: 1.0\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-22 18:27:09,082] Starting new video recorder writing to /home/thomas/Projects/Reinforcement Learning/tmp/breakout-1/openaigym.video.0.4405.video000125.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 216/15000, Step: 222, Iteration: 51750, Reward: 2.00\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-22 18:42:50,332] Starting new video recorder writing to /home/thomas/Projects/Reinforcement Learning/tmp/breakout-1/openaigym.video.0.4405.video000216.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 343/15000, Step: 314, Iteration: 90854, Reward: 2.00\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-22 19:08:14,417] Starting new video recorder writing to /home/thomas/Projects/Reinforcement Learning/tmp/breakout-1/openaigym.video.0.4405.video000343.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 451/15000, Step: 255, Iteration: 130268, Reward: 2.00\r"
     ]
    }
   ],
   "source": [
    "N_EPISODE = 15000\n",
    "loss, mean_q = main(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('Loss')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(loss)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(mean_q)\n",
    "plt.title('Mean Q-Values')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('mean Q value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
