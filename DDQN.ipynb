{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import keras\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn as sk\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import rescale\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *\n",
    "from keras import backend as K\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Global Parameters\n",
    "\n",
    "class DQN_Agent(): \n",
    "    \n",
    "    def __init__(self, num_state, num_action, params):\n",
    "        \n",
    "        self.params =  params\n",
    "        self.num_state = num_state\n",
    "        self.num_action = num_action\n",
    "        self.steps = 0        \n",
    "        self.gamma = params['gamma']   \n",
    "        self.eps_min = params['eps_min']\n",
    "        self.eps_max = params['eps_max']\n",
    "        self.eps = params['eps_max']\n",
    "        self.decay = params['decay']\n",
    "        self.learning_rate = params['lr']\n",
    "        self.batch_size = params['batch_size']\n",
    "        self.capacity = params['capacity']\n",
    "        self.load_model = params['load_model']\n",
    "        self.freq_target = params['freq_target']\n",
    "        self.model = self._create_model(load = self.load_model)\n",
    "        self.target_model= self._create_model(load = self.load_model)\n",
    "        self.memory=[]\n",
    "        \n",
    "    # Model OK    \n",
    "    def _create_model(self, load = False):\n",
    "        \n",
    "        def huber_loss(y_true, y_pred, in_keras=True):\n",
    "            err = y_true - y_pred\n",
    "            delta = 2.0\n",
    "            quadratic_term = 0.5 * err**2\n",
    "            linear_term = delta*(abs(err) - 0.5*delta)\n",
    "            use_linear_term = (abs(err) > 1.0)\n",
    "            \n",
    "            if in_keras:\n",
    "                use_linear_term = K.cast(use_linear_term, 'float32')\n",
    "            #return use_linear_term * linear_term + (1-use_linear_term) * quadratic_term\n",
    "            return quadratic_term\n",
    "            \n",
    "        if not load:\n",
    "            model =  Sequential()\n",
    "\n",
    "            model.add(Conv2D(input_shape = self.num_state, filters = 32, \n",
    "                             kernel_size = 8, strides=2, \n",
    "                             activation = 'relu'))\n",
    "\n",
    "            model.add(Conv2D(filters = 64, kernel_size = 4, strides=2, \n",
    "                             activation = 'relu'))\n",
    "\n",
    "            model.add(Conv2D(filters = 64, kernel_size = 2, strides=1,\n",
    "                             activation = 'relu'))\n",
    "\n",
    "            model.add(Flatten()) \n",
    "            model.add(Dense(units=512, kernel_initializer='glorot_normal',\n",
    "                            activation = 'relu')) \n",
    "            model.add(Dense(self.num_action))              \n",
    "\n",
    "            optimizer = Adam(lr = self.learning_rate)\n",
    "            model.compile(optimizer = optimizer, loss = huber_loss)\n",
    "\n",
    "            print(\"Model constructed...\", end =\"\\r\", flush=True)\n",
    "        else: \n",
    "            model = load_model('dqn-atari.h5', custom_objects={'huber_loss' : huber_loss})\n",
    "            print(\"Model loaded...\", end =\"\\r\", flush=True)\n",
    "        \n",
    "        return model   \n",
    "    \n",
    "    def update_target_model(self):\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "    \n",
    "    # Check OK\n",
    "    def predict(self, state):        \n",
    "        if len(state.shape) == 3:\n",
    "            state = np.expand_dims(state, axis=0)\n",
    "        return self.model.predict(state)\n",
    "    \n",
    "    def predict_target(self, state):        \n",
    "        if len(state.shape) == 3:\n",
    "            state = np.expand_dims(state, axis=0)\n",
    "        return self.target_model.predict(state)\n",
    "    \n",
    "    # Check OK\n",
    "    def observe(self, state, action, next_state, reward, done):\n",
    "        self.memory.append((state, action, next_state, reward, done))    \n",
    "        \n",
    "        if len(self.memory) > self.capacity:\n",
    "            self.memory.pop(0)\n",
    "    \n",
    "        self.eps = self.eps_min + (self.eps_max - self.eps_min) * math.exp(-self.steps * self.decay)        \n",
    "        self.steps +=1 \n",
    "        \n",
    "        if self.steps % self.freq_target ==0:\n",
    "            self.update_target_model()\n",
    "        \n",
    "    # Check OK    \n",
    "    def act(self, state):      \n",
    "        if np.random.rand() < self.eps:\n",
    "            return np.random.choice(self.num_action)\n",
    "        else:            \n",
    "            return np.argmax(self.predict(state))                 \n",
    "    \n",
    "    def replay(self):                \n",
    "        batch_len = min(self.batch_size, len(self.memory))        \n",
    "        batch = np.array(random.sample(self.memory, batch_len))        \n",
    "        \n",
    "        state = np.array([episode[0] for episode in batch])\n",
    "        action =  np.array([episode[1] for episode in batch])\n",
    "        next_state = np.array([episode[2] for episode in batch])\n",
    "        reward =  np.array([episode[3] for episode in batch])\n",
    "        done = np.array([episode[4] for episode in batch])\n",
    "        \n",
    "        q = np.array(self.predict(state))\n",
    "        q_ = np.array(self.predict_target(next_state))\n",
    "        \n",
    "        for i in range(batch_len):\n",
    "            q[i][action[i]] = reward[i]+ self.gamma*np.max(q_[i])* (1-done[i]) \n",
    "            \n",
    "        history = self.model.fit(state, q, \n",
    "                   verbose = 0, epochs=1, shuffle = False, batch_size = 32) \n",
    "        return history, np.mean(q, axis = 0)\n",
    "\n",
    "\n",
    "class input_pipeline():    \n",
    "    \n",
    "    def __init__(self, state):       \n",
    "        self.history_length = 4        \n",
    "        self.input_x=[]\n",
    "        self.input_x = [self._preprocess(state) for i in range(self.history_length)]\n",
    "        self.x = np.moveaxis(np.array(self.input_x), 0, -1) \n",
    "\n",
    "    def _preprocess(self, state):    \n",
    "        \n",
    "        state = np.mean(state, axis = 2).astype(np.uint8)\n",
    "        state = state[::2, ::2]\n",
    "        state = state[15:97,3:77]\n",
    "        state[state==162] = 80\n",
    "        state[state==180] = 90\n",
    "        state[state==198] = 100\n",
    "        state[state==200] = 110   \n",
    "        return state / 255\n",
    "    \n",
    "    def update(self, state):\n",
    "        self.input_x.pop(0)\n",
    "        self.input_x.append(self._preprocess(state))\n",
    "        self.x = np.moveaxis(np.array(self.input_x), 0, -1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(train=True):\n",
    "    \n",
    "    env = gym.make('BreakoutDeterministic-v4')\n",
    "    env = gym.wrappers.Monitor(env, './tmp/breakout-2', force=True)\n",
    "    num_state = env.observation_space.shape    \n",
    "    num_action = env.action_space.n\n",
    "    \n",
    "    agent = DQN_Agent((82,74,4), num_action, params) \n",
    "    loss, mean_av, render = [], [], False    \n",
    "    \n",
    "    for episode in range(N_EPISODE):        \n",
    "        state, step, total_reward, done, render = env.reset(), 0, 0, False, False        \n",
    "        pipeline = input_pipeline(state)\n",
    "       \n",
    "        if episode > 5000:\n",
    "            render = True\n",
    "        \n",
    "        while not done:\n",
    "            if render:\n",
    "                env.render()\n",
    "                \n",
    "            state = pipeline.x\n",
    "            action = agent.act(state)            \n",
    "            next_state, reward, done, _ = env.step(action)  \n",
    "            \n",
    "            pipeline.update(next_state)\n",
    "            next_state = pipeline.x             \n",
    "            total_reward += reward\n",
    "            step +=1\n",
    "            \n",
    "            if train and step >= 4 :    \n",
    "                agent.observe(state, action, next_state, np.sign(reward), done)            \n",
    "                history, mean_action_value = agent.replay()\n",
    "                loss.append(history.history['loss'])\n",
    "                mean_av.append(np.mean(mean_action_value))                \n",
    "        \n",
    "        if episode % 10==0:\n",
    "            agent.model.save('dqn-atari.h5')\n",
    "        \n",
    "        print('Episode: {}/{}, Step: {}, Iteration: {}, Eps: {:.4f}, Reward: {}'\n",
    "              .format(episode+1, N_EPISODE, step, agent.steps, agent.eps, total_reward), \n",
    "              end = '\\r', flush = True) \n",
    "        \n",
    "    return np.array(loss), np.array(mean_av)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['gamma'] = 0.99\n",
    "params['eps_min'] = 0.05\n",
    "params['eps_max'] = 1.00\n",
    "params['decay'] = 1e-5\n",
    "params['batch_size'] = 128\n",
    "params['lr'] = 0.00025\n",
    "params['capacity'] = 50000\n",
    "params['freq_target'] = 10000\n",
    "params['load_model'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEYCAYAAABGJWFlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe9be532518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.array(range(1000000))\n",
    "y = params['eps_min'] + (params['eps_max']-params['eps_min'])*np.exp(-params['decay']*x)\n",
    "plt.plot(y)\n",
    "plt.title('$\\epsilon$ decay rate')\n",
    "plt.ylabel('epsilon')\n",
    "plt.xlabel('iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-25 07:05:31,124] Making new env: BreakoutDeterministic-v4\n",
      "[2017-11-25 07:05:31,258] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded...\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-25 07:05:32,263] Starting new video recorder writing to /home/thomas/Projects/Reinforcement Learning/tmp/breakout-2/openaigym.video.0.4655.video000000.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1/10000000, Step: 180, Iteration: 177, Eps: 0.9983, Reward: 1.0\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-25 07:05:42,193] Starting new video recorder writing to /home/thomas/Projects/Reinforcement Learning/tmp/breakout-2/openaigym.video.0.4655.video000001.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 8/10000000, Step: 132, Iteration: 1404, Eps: 0.9868, Reward: 0.0\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-25 07:07:10,259] Starting new video recorder writing to /home/thomas/Projects/Reinforcement Learning/tmp/breakout-2/openaigym.video.0.4655.video000008.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 27/10000000, Step: 190, Iteration: 4807, Eps: 0.9554, Reward: 2.0\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-25 07:11:15,613] Starting new video recorder writing to /home/thomas/Projects/Reinforcement Learning/tmp/breakout-2/openaigym.video.0.4655.video000027.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 64/10000000, Step: 126, Iteration: 11536, Eps: 0.8965, Reward: 0.0\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-25 07:19:17,618] Starting new video recorder writing to /home/thomas/Projects/Reinforcement Learning/tmp/breakout-2/openaigym.video.0.4655.video000064.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 69/10000000, Step: 196, Iteration: 12462, Eps: 0.8887, Reward: 2.0\r"
     ]
    }
   ],
   "source": [
    "N_EPISODE = 10000000\n",
    "loss, mean_q = main(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('Loss')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(loss)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(mean_q)\n",
    "plt.title('Mean Q-Values')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('mean Q value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
